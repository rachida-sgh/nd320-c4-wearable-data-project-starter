{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "def BandpassFilter(signal, bandpass, fs):\n",
    "    \"\"\"\n",
    "    Filter bandpass for unrealistic heart rate values.\n",
    "    Args:\n",
    "        signal: numpy array. Signal to process.\n",
    "        pass_band: tuple. band width for filter in Hz   \n",
    "        fs: int. Sampling frequency in Hz\n",
    "    Returns:\n",
    "        numpy array. Filtered signal\n",
    "    \"\"\"\n",
    "    b, a = scipy.signal.butter(3, bandpass, btype='bandpass', fs=fs)\n",
    "    return scipy.signal.filtfilt(b, a, signal)\n",
    "\n",
    "\n",
    "def ComputeSpectogram(signal, window, overlap, fs):\n",
    "    \"\"\"\n",
    "    Compute Spectogram\n",
    "    \n",
    "    Args:\n",
    "        signal: numpy array. Signal to process\n",
    "        window: int. Window in seconds used to collect the data\n",
    "        overlap: int. Overlap in seconds between consecutive windows   \n",
    "        fs: int. Sampling frequency in Hz. Default is 125 Hz\n",
    "    \n",
    "    Returns:\n",
    "        spectorgram (FTT)\n",
    "    \"\"\"\n",
    "    nfft_window = fs * window\n",
    "    noverlap = fs * overlap\n",
    "    spectrum, freqs, _, _ = plt.specgram(signal, NFFT=nfft_window, Fs=fs, noverlap=noverlap)\n",
    "    plt.close()\n",
    "    return spectrum, freqs\n",
    "\n",
    "def ComputeFreqPeaks(spectrum, freqs, max_freq):\n",
    "    \"\"\"\n",
    "    Compute peaks of the spectogram\n",
    "    \n",
    "    Args:\n",
    "        spectrum: 2D array . Spectogram\n",
    "        freqs: 1D array. The frequencies corresponding to the rows in Spectrum.\n",
    "\n",
    "    Optional Arg:    \n",
    "        max_freq: int. Maximum frequency used to find peaks. Default is 5 Hz\n",
    "    \n",
    "    Returns:\n",
    "        A list of the peaks (frequences) for each time window sorted by dominance\n",
    "    \"\"\"\n",
    "\n",
    "    peaks = []\n",
    "    \n",
    "    # For a FFT signal of each time window\n",
    "    for current_window in range(spectrum.shape[1]):\n",
    "\n",
    "        # Use Frequencies <= max_freq\n",
    "        current_spectrum = spectrum[:, current_window]\n",
    "    \n",
    "        # A peak is must have a height > 10% of the highest peak\n",
    "        peak_indices = sp.signal.find_peaks(current_spectrum, height=np.max(np.abs(current_spectrum)*0.1))[0]\n",
    "\n",
    "        # Sort peaks by descendent dominance\n",
    "        sorted_indices = np.argsort(current_spectrum[peak_indices])[::-1]\n",
    "\n",
    "        peaks.append(freqs[peak_indices[sorted_indices]])\n",
    "        \n",
    "    return peaks\n",
    "\n",
    "\n",
    "def ComputePulseRates(signals_peaks, similarity_1=1, similarity_2=0, last_n_estimates=3):\n",
    "    \"\"\"\n",
    "    Compute pulse rate estimation given the peaks of the spectorgrams\n",
    "    of ppg, accx, accy, and accz signals\n",
    "    \n",
    "    Args:\n",
    "        signal peaks: a dictioray of spectoragms peaks\n",
    "        similarity_1: similarity to compare ppg and acc dominant frequencies\n",
    "        similarity_2: similarity to compare dominant ppg frequencies between windows\n",
    "        last_n_estimates: number of previous windows used to smooth pulse rate\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "        a numpy array of pulse rate estimations per time window (in bmp)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    max_ppg_freqs = []\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    for ppg, accx, accy, accz in zip(signals_peaks[\"ppg\"], signals_peaks[\"accx\"], signals_peaks[\"accy\"], signals_peaks[\"accz\"]):\n",
    "        \n",
    "        # Get the dominant ppg frequency for the current window\n",
    "        current_ppg = list(ppg)\n",
    "        dominant_ppg = current_ppg[0]\n",
    "        dominant_accs = [accx[0], accy[0], accz[0]]\n",
    "        ppg_acc_similarity = [abs(max_acc - dominant_ppg) <= similarity_2 for max_acc in dominant_accs]\n",
    "\n",
    "        # When the dominant accelerometer frequency is the same as the PPG\n",
    "        # pick the next strongest PPG frequency if there is another good candidate\n",
    "        while (sum(ppg_acc_similarity) > 0) and (len(current_ppg) >= 2) :\n",
    "            current_ppg = current_ppg[1:]\n",
    "            # print(i, current_ppg)\n",
    "            dominant_ppg = current_ppg[0]\n",
    "            ppg_acc_similarity = [abs(dom_acc - dominant_ppg) <= similarity_2 for dom_acc in dominant_accs]\n",
    "            # print(i, max_ppg )\n",
    "        \n",
    "        # If all ppg peaks are similar to the acc peaks chose the most dominant\n",
    "        # ppg peak as pulse rate estimate\n",
    "        if len(current_ppg) == 1:\n",
    "            dominant_ppg = ppg[0]\n",
    "\n",
    "        # Smooth out the rate estimates\n",
    "        if i >= last_n_estimates and abs(dominant_ppg - max_ppg_freqs[i-1]) >=  similarity_1:\n",
    "            dominant_ppg = sum(max_ppg_freqs[-last_n_estimates:]) / last_n_estimates\n",
    "\n",
    "\n",
    "        max_ppg_freqs.append(dominant_ppg)\n",
    "        i += 1\n",
    "\n",
    "    return np.array(max_ppg_freqs) * 60 # Converted to bpm\n",
    "\n",
    "def ComputeConfidences(pulse_rate_estimates, ppg_spectrum, ppg_freqs, bpm_confidence):\n",
    "    \"\"\"\n",
    "    Compute the confidence in the pulse rate estimations given a bpm confidence interval\n",
    "    \n",
    "    Args:\n",
    "        pulse_rate_estimates: numpy array of pulse rate estimate per time window (bpm)\n",
    "        ppg_spectrum: ppg spectrum\n",
    "        ppg_freqs: ppg frequencies \n",
    "        bpm_confidence: bmp interval to compute confidence\n",
    "    Returns:\n",
    "        numpy array of confidence per time window\n",
    "    \"\"\"\n",
    "    \n",
    "    confidences = []\n",
    "\n",
    "    for i in range(len(pulse_rate_estimates)):\n",
    "        pulse_rate = pulse_rate_estimates[i]\n",
    "        spectrum = ppg_spectrum[:, i]\n",
    "        lower_conf_window = pulse_rate - bpm_confidence\n",
    "        upper_conf_window = pulse_rate + bpm_confidence\n",
    "        confidence_window = (ppg_freqs >= lower_conf_window) & (ppg_freqs <= upper_conf_window)\n",
    "        confidence = np.sum(spectrum[confidence_window]) / np.sum(spectrum)\n",
    "        confidences.append(confidence)\n",
    "    \n",
    "    return np.array(confidences)\n",
    "\n",
    "def ComputeErrors(pulse_rate_estimates, ecg):\n",
    "    \"\"\"\n",
    "    Compute Mean Avergae Error (MAE) in bmp between the pulse rate estimates\n",
    "    and a reference pulse rate\n",
    "    \n",
    "    Args:\n",
    "        pulse_rate_estimates: numpy array of pulse rate estimation per window (bpm)\n",
    "        ecg: numpy array of ground thruth pulse rate per window (bpm)\n",
    "    \n",
    "    Returns:\n",
    "        MAE in bpm\n",
    "    \n",
    "    \"\"\"\n",
    "    length = pulse_rate_estimates.shape[0]\n",
    "    pulse_rate_estimates = pulse_rate_estimates.reshape(1, length)\n",
    "    ecg = ecg.reshape(1, length)\n",
    "    errors = pulse_rate_estimates - ecg\n",
    "    return errors.tolist()[0]\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    \"\"\"\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Args:\n",
    "        data_fl: a path of the .mat files that contain signal data\n",
    "        ref_fl: a path of the .mat files that contain reference data\n",
    "    \n",
    "    Returns:\n",
    "        A 2-tuple of numpy arrays of per-estimate mean absolute error and confidence as a .\n",
    "    \"\"\"\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    ecg = sp.io.loadmat(ref_fl)['BPM0'].flatten()\n",
    "\n",
    "    signals = {\n",
    "        \"ppg\" : ppg,\n",
    "        \"accx\": accx,\n",
    "        \"accy\": accy,\n",
    "        \"accz\": accz,\n",
    "    }\n",
    "\n",
    "    fs = 125\n",
    "    low_freq = 40/60\n",
    "    high_freq = 240/60\n",
    "    window = 8\n",
    "    overlap = 6\n",
    "    max_freq = 5\n",
    "    bpm_confidence = 15\n",
    "    \n",
    "    # Compute per window peaks for each signal\n",
    "    signals_peaks = {}\n",
    "    bandpass = (low_freq, high_freq)\n",
    "    for key, signal in signals.items():\n",
    "        filtered_signal = BandpassFilter(signal, bandpass=bandpass,fs=fs)\n",
    "        spectrum, freqs = ComputeSpectogram(filtered_signal, window=window, overlap=overlap, fs=fs)\n",
    "        signals_peaks[key] = ComputeFreqPeaks(spectrum=spectrum, freqs=freqs, max_freq=max_freq)\n",
    "        # Store spectrum data only for ppg signal\n",
    "        if key == \"ppg\":\n",
    "            ppg_freqs = freqs\n",
    "            ppg_spectrum = spectrum\n",
    "\n",
    "    # Compute per window pulse rate estiame in bpm\n",
    "    pulse_rate_estimates = ComputePulseRates(signals_peaks)\n",
    "    # Compute per window errors\n",
    "    errors = ComputeErrors(pulse_rate_estimates, ecg)\n",
    "    # Compute per window confidence\n",
    "    confidences = ComputeConfidences(pulse_rate_estimates, ppg_spectrum, ppg_freqs, bpm_confidence)\n",
    "    #   pulse_rate_estimates, ecg, signals_peaks\n",
    "    return errors, confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.901684582495966"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description** - Include details so someone unfamiliar with your project will know how to run your code and use your algorithm. \n",
    "> - **Data Description** - Describe the dataset that was used to train and test the algorithm. Include its short-comings and what data would be required to build a more complete dataset.\n",
    "> - **Algorithhm Description** will include the following:\n",
    ">   - how the algorithm works\n",
    ">   - the specific aspects of the physiology that it takes advantage of\n",
    ">   - a describtion of the algorithm outputs\n",
    ">   - caveats on algorithm outputs \n",
    ">   - common failure modes\n",
    "> - **Algorithm Performance** - Detail how performance was computed (eg. using cross-validation or train-test split) and what metrics were optimized for. Include error metrics that would be relevant to users of your algorithm. Caveat your performance numbers by acknowledging how generalizable they may or may not be on different datasets.\n",
    "\n",
    "- **Code Description**\n",
    "\n",
    "Run the first cell to load all the functions required for the pulse rate estimation algorithm and the second cell to run the evaluation function.\n",
    "\n",
    "The evaluation functions first loads the Troika data, runs the estimation algorithm and returns the Mean Average Error at 90% confidence.\n",
    "\n",
    "- **Data Description**\n",
    "\n",
    "We use the [Troika](https://ieeexplore.ieee.org/document/6905737) dataset. It contains 12 data points. Each of these data point comes with the PPG signal, the 3-axis accelerometer signals, and a reference ecg signal.\n",
    "\n",
    "- **Algorithn Description**\n",
    "\n",
    "We take advantage of the following physiologic aspects:\n",
    " 1. The light emitted by the PPG sensor is absorbed by red blood cells in these capilaries and the photodetector will see the drop in reflected light. When the blood returns to the heart, fewer red blood cells in the wrist absorb the light and the photodetector sees an increase in reflected light. The period of this oscillating waveform is the pulse rate.\n",
    " 2. The PPG sensor also register blood pressure due to the arm motion during activities like walking and runninng. The accelerometer register the periodic movement of these activities and make it possible to filter them out from the PPG signal.\n",
    "\n",
    "The algorithm takes the PPG and the 3-axis accelerometer signals as input and outputs the pulse rate estimation for each time window. It follows these steps:\n",
    " 1. Filter the PPG signal and the 3-axis accelerometer signals to keep the frequencies between the range of 40-240 bpm.\n",
    " 2. Compute the spectograms for each of the signals.\n",
    " 3. Estimate the pulse rate use the dominant frequency from the PPG spectogram. However, uf the first dominant ppg frequency is similar to one the dominant frequency of any accelerometer signals, we use the next dominant frequency of the ppg spectogram as an estimation. If all the dominant PPG frequencies are similar to the accelerometer, we pick the dominant PGG frequency.\n",
    "    \n",
    "Caveats and common failure mode:\n",
    " 1. The algorithm doesn't accound for body movements like the fingers movements because they can't be capture by the accelerometer.\n",
    " 2. The agorithm could perform poorly of periodic body movenment other then running. The training set contains ideed only accelerometer signals of running on a trademill.\n",
    " 3. The algorithm doesn't account for additional sources of noice like surrounding light and displacement of the PPG sensor on the hand.\n",
    " 4. The algortim doesn't account for non periodic movement captured by the sensor.\n",
    "\n",
    "- **Algorithm Performance**\n",
    "\n",
    "The Mean Absolute Error at 90% availabiliy is 14.9 BPM, which lower than the minimum required MAE (15 BPM) on the training set. This MAE is 7BPM on the test set.\n",
    "\n",
    "We compute the average absoulte difference between the estimated pulse rate and a reference pulse rate fron an ECG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** (back in the Project Classroom) to apply a unit test to confirm that your algorithm met the success criteria. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./passed.png\" alt=\"Alternative text\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
